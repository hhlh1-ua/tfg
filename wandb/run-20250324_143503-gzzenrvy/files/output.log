P_03
P_04
P_05
P_06
P_09
P_10
P_12
P_13
P_14
P_18
P_19
P_20
P_01
P_02
P_16
P_17
P_07
P_08
P_11
P_15
Extracting video features for the val split ...
video: P_01 start frame:239, end frame:989, initially selected frames: 150, finally selected frames:144
Traceback (most recent call last):
  File "main.py", line 65, in <module>
    main()
  File "main.py", line 49, in main
    model.get_features(val_ds)
  File "/workspace/tfg_hhernandez/models/VideoFeaturesExtractor.py", line 107, in get_features
    output = self.model(**inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/timesformer/modeling_timesformer.py", line 636, in forward
    encoder_outputs = self.encoder(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/timesformer/modeling_timesformer.py", line 442, in forward
    layer_outputs = layer_module(hidden_states, output_attentions)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/timesformer/modeling_timesformer.py", line 379, in forward
    spatial_attention_outputs = self.attention(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/timesformer/modeling_timesformer.py", line 249, in forward
    self_outputs = self.attention(hidden_states, output_attentions)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/timesformer/modeling_timesformer.py", line 209, in forward
    attention_probs = (query @ key.transpose(-2, -1)) * self.scale
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.46 GiB. GPU
