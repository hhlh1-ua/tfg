preprocessor_config.json: 100%|█████████████████████████████████████████████████████████████████████| 271/271 [00:00<00:00, 32.8kB/s]
config.json: 100%|██████████████████████████████████████████████████████████████████████████████████| 725/725 [00:00<00:00, 91.2kB/s]
model.safetensors: 100%|███████████████████████████████████████████████████████████████████████████| 377M/377M [00:03<00:00, 112MB/s]
Extracting video features for the train split ...
video: P_03, start frame:389, end frame:3086, actions: ['dental floss'], selected frames:16, block number: 0
video: P_03, start frame:389, end frame:3086, actions: ['dental floss'], selected frames:16, block number: 1
video: P_03, start frame:389, end frame:3086, actions: ['dental floss'], selected frames:16, block number: 2
video: P_03, start frame:389, end frame:3086, actions: ['dental floss'], selected frames:16, block number: 3
video: P_03, start frame:389, end frame:3086, actions: ['dental floss'], selected frames:16, block number: 4
Traceback (most recent call last):
  File "../main.py", line 160, in <module>
    main()
  File "../main.py", line 131, in main
    video_model.get_features(train_ds)
  File "/workspace/tfg_hhernandez/models/VideoFeaturesExtractor.py", line 71, in get_features
    inputs = self.image_processor(images=frames, return_tensors="pt")
  File "/usr/local/lib/python3.8/dist-packages/transformers/image_processing_utils.py", line 41, in __call__
    return self.preprocess(images, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/utils/generic.py", line 852, in wrapper
    return func(*args, **valid_kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/videomae/image_processing_videomae.py", line 322, in preprocess
    videos = [
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/videomae/image_processing_videomae.py", line 323, in <listcomp>
    [
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/videomae/image_processing_videomae.py", line 324, in <listcomp>
    self._preprocess_image(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/videomae/image_processing_videomae.py", line 221, in _preprocess_image
    image = self.resize(image=image, size=size, resample=resample, input_data_format=input_data_format)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/videomae/image_processing_videomae.py", line 169, in resize
    return resize(
  File "/usr/local/lib/python3.8/dist-packages/transformers/image_transforms.py", line 338, in resize
    image = to_pil_image(image, do_rescale=do_rescale, input_data_format=input_data_format)
  File "/usr/local/lib/python3.8/dist-packages/transformers/image_transforms.py", line 216, in to_pil_image
    return PIL.Image.fromarray(image, mode=image_mode)
  File "/usr/local/lib/python3.8/dist-packages/PIL/Image.py", line 3154, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/usr/local/lib/python3.8/dist-packages/PIL/Image.py", line 3069, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/usr/local/lib/python3.8/dist-packages/PIL/Image.py", line 3003, in frombytes
    im = new(mode, size)
  File "/usr/local/lib/python3.8/dist-packages/PIL/Image.py", line 2974, in new
    return im._new(core.fill(mode, size, color))
KeyboardInterrupt
