loading checkpoint '/results/multimodal/timesformer/objs_text/first_frame/concat/vit_bert/best_epoch.pt'
Traceback (most recent call last):
  File "../main.py", line 160, in <module>
    main()
  File "../main.py", line 148, in main
    avg_loss,top1,top5 = test_model(config,test_ds)
  File "/workspace/tfg_hhernandez/utils/evaluate.py", line 68, in test_model
    model.load_state_dict(checkpoint['model_state_dict'])
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 2189, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for Model:
	Unexpected key(s) in state_dict: "fusion_strategy.linear_video.0.weight", "fusion_strategy.linear_video.0.bias", "fusion_strategy.linear_video.1.weight", "fusion_strategy.linear_video.1.bias", "ObjFTExtractor.linear_object.0.weight", "ObjFTExtractor.linear_object.0.bias", "ObjFTExtractor.linear_object.1.weight", "ObjFTExtractor.linear_object.1.bias", "ObjFTExtractor.linear_text.0.weight", "ObjFTExtractor.linear_text.0.bias", "ObjFTExtractor.linear_text.1.weight", "ObjFTExtractor.linear_text.1.bias", "ObjFTExtractor.transformer_encoder.layers.0.self_attn.in_proj_weight", "ObjFTExtractor.transformer_encoder.layers.0.self_attn.in_proj_bias", "ObjFTExtractor.transformer_encoder.layers.0.self_attn.out_proj.weight", "ObjFTExtractor.transformer_encoder.layers.0.self_attn.out_proj.bias", "ObjFTExtractor.transformer_encoder.layers.0.linear1.weight", "ObjFTExtractor.transformer_encoder.layers.0.linear1.bias", "ObjFTExtractor.transformer_encoder.layers.0.linear2.weight", "ObjFTExtractor.transformer_encoder.layers.0.linear2.bias", "ObjFTExtractor.transformer_encoder.layers.0.norm1.weight", "ObjFTExtractor.transformer_encoder.layers.0.norm1.bias", "ObjFTExtractor.transformer_encoder.layers.0.norm2.weight", "ObjFTExtractor.transformer_encoder.layers.0.norm2.bias", "ObjFTExtractor.transformer_encoder.layers.1.self_attn.in_proj_weight", "ObjFTExtractor.transformer_encoder.layers.1.self_attn.in_proj_bias", "ObjFTExtractor.transformer_encoder.layers.1.self_attn.out_proj.weight", "ObjFTExtractor.transformer_encoder.layers.1.self_attn.out_proj.bias", "ObjFTExtractor.transformer_encoder.layers.1.linear1.weight", "ObjFTExtractor.transformer_encoder.layers.1.linear1.bias", "ObjFTExtractor.transformer_encoder.layers.1.linear2.weight", "ObjFTExtractor.transformer_encoder.layers.1.linear2.bias", "ObjFTExtractor.transformer_encoder.layers.1.norm1.weight", "ObjFTExtractor.transformer_encoder.layers.1.norm1.bias", "ObjFTExtractor.transformer_encoder.layers.1.norm2.weight", "ObjFTExtractor.transformer_encoder.layers.1.norm2.bias".
	size mismatch for MLP.model.0.weight: copying a param with shape torch.Size([512, 3840]) from checkpoint, the shape in current model is torch.Size([512, 768]).
